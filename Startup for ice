#!/bin/bash

# Script to trigger in-place Hive-to-Iceberg migration using PySpark
script_name=$(basename "$0")

function usage() {
    echo "Usage: $script_name -i <hive_database> -t <table_list> [-v] [-d]"
    echo "  -i    Hive database name (required)"
    echo "  -t    Table list (comma-separated) to migrate (required)"
    echo "  -v    Enable validation after migration"
    echo "  -d    Dry run mode (show commands without execution)"
    exit 1
}

# Default variables
validation=false
dry_run=0

# Parse input arguments
while getopts "i:t:vd" option; do
    case "$option" in
        i) hive_db="$OPTARG" ;;   # Source and target database (same)
        t) tables="$OPTARG" ;;    # List of tables to migrate
        v) validation=true ;;     # Enable validation flag
        d) dry_run=1 ;;           # Dry run mode
        *) usage ;;
    esac
done

# Input validation
if [[ -z "$hive_db" || -z "$tables" ]]; then
    usage
fi

# Spark submit command template
spark_submit_cmd="spark-submit \
    --master yarn \
    --deploy-mode cluster \
    --executor-memory 8G \
    --num-executors 4 \
    --executor-cores 2"

# PySpark Migration Script Path
migration_script="iceberg_migration.py"

# Split tables and start migration
IFS=',' read -ra TABLE_ARRAY <<< "$tables"

for table in "${TABLE_ARRAY[@]}"; do
    echo "Starting in-place migration for table: $table in database: $hive_db"
    cmd="$spark_submit_cmd $migration_script \
        --source-db $hive_db \
        --table-name $table \
        --target-db $hive_db \
        --validate $validation"

    if [[ $dry_run -eq 1 ]]; then
        echo "[Dry Run] $cmd"
    else
        echo "Running migration for $table..."
        eval "$cmd"
        if [[ $? -ne 0 ]]; then
            echo "Error during migration of table: $table"
            exit 1
        fi
    fi
done

echo "In-place Hive-to-Iceberg migration completed successfully!"




$$$$$


#!/bin/bash

# Script to trigger Hive-to-Iceberg migration using PySpark
script_name=$(basename "$0")

# Hardcoded Python migration script path
pyspark_script="/path/to/iceberg_migration.py"  # Update this to your actual path

function usage() {
    echo "Usage: $script_name --table-names <table_list> [options]"
    echo "  Options:"
    echo "    --migrate-table            Migrate the Hive table to Iceberg format"
    echo "    --validate                 Validate the data integrity after migration"
    echo "    --delete-backup-table      Drop any backup tables after migration"
    echo "    --handle-timestamps        Handle Hive timestamps without timezone"
    echo "    --format-version <version> Specify the Iceberg format version (default: 2)"
    exit 1
}

# Default variables
migrate_table=false
validate_data=false
delete_backup=false
handle_timestamps=false
format_version=2  # Default format version

# Parse input arguments
while [[ "$#" -gt 0 ]]; do
    case "$1" in
        --table-names) table_names="$2"; shift ;;
        --migrate-table) migrate_table=true ;;
        --validate) validate_data=true ;;
        --delete-backup-table) delete_backup=true ;;
        --handle-timestamps) handle_timestamps=true ;;
        --format-version) format_version="$2"; shift ;;
        *) usage ;;
    esac
    shift
done

# Input validation
if [[ -z "$table_names" ]]; then
    usage
fi

# Spark submit command template
spark_submit_cmd="spark-submit \
    --master yarn \
    --deploy-mode cluster \
    --executor-memory 8G \
    --num-executors 4 \
    --executor-cores 2"

# Split table names
IFS=',' read -ra TABLE_ARRAY <<< "$table_names"

for table in "${TABLE_ARRAY[@]}"; do
    echo "Starting migration for table: $table"

    # Construct PySpark command
    cmd="$spark_submit_cmd $pyspark_script \
        --table-name $table \
        --format-version $format_version"

    if [[ "$migrate_table" == true ]]; then
        cmd+=" --migrate-table"
    fi

    if [[ "$validate_data" == true ]]; then
        cmd+=" --validate"
    fi

    if [[ "$delete_backup" == true ]]; then
        cmd+=" --delete-backup-table"
    fi

    if [[ "$handle_timestamps" == true ]]; then
        cmd+=" --handle-timestamps"
    fi

    echo "Running command: $cmd"
    eval "$cmd"

    if [[ $? -ne 0 ]]; then
        echo "Error during migration for table: $table"
        exit 1
    fi
done

echo "Hive-to-Iceberg migration completed successfully!"




#######


#!/bin/bash

# Script to trigger Hive-to-Iceberg migration using PySpark
script_name=$(basename "$0")

function usage() {
    echo "Usage: $script_name -f <pyspark_script> --table-names <table_list> [options]"
    echo "  Options:"
    echo "    --migrate-table            Migrate the Hive table to Iceberg format"
    echo "    --validate                 Validate the data integrity after migration"
    echo "    --delete-backup-table      Drop any backup tables after migration"
    echo "    --handle-timestamps        Handle Hive timestamps without timezone"
    echo "    --format-version <version> Specify the Iceberg format version (e.g., 1 or 2)"
    exit 1
}

# Default variables
migrate_table=false
validate_data=false
delete_backup=false
handle_timestamps=false
format_version=2  # Default format version

# Parse input arguments
while [[ "$#" -gt 0 ]]; do
    case "$1" in
        -f) pyspark_script="$2"; shift ;;
        --table-names) table_names="$2"; shift ;;
        --migrate-table) migrate_table=true ;;
        --validate) validate_data=true ;;
        --delete-backup-table) delete_backup=true ;;
        --handle-timestamps) handle_timestamps=true ;;
        --format-version) format_version="$2"; shift ;;
        *) usage ;;
    esac
    shift
done

# Input validation
if [[ -z "$pyspark_script" || -z "$table_names" ]]; then
    usage
fi

# Spark submit command template
spark_submit_cmd="spark-submit \
    --master yarn \
    --deploy-mode cluster \
    --executor-memory 8G \
    --num-executors 4 \
    --executor-cores 2"

# Split table names
IFS=',' read -ra TABLE_ARRAY <<< "$table_names"

for table in "${TABLE_ARRAY[@]}"; do
    echo "Starting migration for table: $table"

    # Construct PySpark command
    cmd="$spark_submit_cmd $pyspark_script \
        --table-name $table \
        --format-version $format_version"

    if [[ "$migrate_table" == true ]]; then
        cmd+=" --migrate-table"
    fi

    if [[ "$validate_data" == true ]]; then
        cmd+=" --validate"
    fi

    if [[ "$delete_backup" == true ]]; then
        cmd+=" --delete-backup-table"
    fi

    if [[ "$handle_timestamps" == true ]]; then
        cmd+=" --handle-timestamps"
    fi

    echo "Running command: $cmd"
    eval "$cmd"

    if [[ $? -ne 0 ]]; then
        echo "Error during migration for table: $table"
        exit 1
    fi
done

echo "Hive-to-Iceberg migration completed successfully!"
