Yes, RewriteTablePath in Iceberg is designed to automatically update the path references in all metadata files, including old metadata (Avro) files, without requiring manual edits.

ğŸ”¹ What RewriteTablePath Does Automatically

When you run:

Actions.forTable(icebergTable)
    .rewriteTablePath()
    .withLocation("o3fs://mybucket.omservice/iceberg_table/")
    .execute();

Iceberg will:
âœ… Update the tableâ€™s root location (location in metadata.json).
âœ… Rewrite all metadata references (including manifest-list and manifest files).
âœ… Ensure old snapshots and history remain intact.
âœ… Change all data file paths inside Avro metadata files (snap-*.avro, manifest-*.avro).

ğŸ” How It Works Internally
	1.	Reads existing metadata (vX.metadata.json).
	2.	Scans all referenced manifest lists (snap-XXXX.avro) and manifests (manifest-XXXX.avro).
	3.	Rewrites all file paths in metadata & Avro files (from HDFS â†’ Ozone).
	4.	Commits the new metadata location to the Iceberg catalog.
	5.	Preserves snapshots & history, so old table versions remain accessible.

ğŸ“Œ Does It Change Old Metadata Files?

Metadata File	Does RewriteTablePath Update It?
vX.metadata.json	âœ… Yes, updates location
snap-XXXX.avro (manifest list)	âœ… Yes, updates file paths
manifest-XXXX.avro (manifest)	âœ… Yes, updates file paths
data/*.parquet	âŒ No, assumes data is already moved

ğŸš€ When Should You Use RewriteTablePath?

âœ… Best Option If:
	â€¢	You are moving the entire Iceberg table (data & metadata) from HDFS â†’ Ozone.
	â€¢	You want to preserve table history and snapshots.
	â€¢	You donâ€™t want to manually edit Avro files.

âŒ When It Wonâ€™t Work:
	â€¢	If you only move metadata files (not data files), Iceberg still expects data to be in the old location.
	â€¢	If you donâ€™t have write permissions to the Iceberg catalog.
	â€¢	If your Iceberg catalog doesnâ€™t support table path rewrites (some Hive-based catalogs may not support it).

ğŸ”¥ Recommended Migration Workflow (HDFS â†’ Ozone)

1ï¸âƒ£ Move Data & Metadata to Ozone

hdfs dfs -cp -f hdfs://namenode/user/hive/warehouse/iceberg_table/ \
    o3fs://mybucket.omservice/iceberg_table/

2ï¸âƒ£ Run RewriteTablePath

Actions.forTable(icebergTable)
    .rewriteTablePath()
    .withLocation("o3fs://mybucket.omservice/iceberg_table/")
    .execute();

3ï¸âƒ£ Verify Migration

Run:

SELECT * FROM iceberg_table.snapshots;
SELECT COUNT(*) FROM iceberg_table;

ğŸ¯ Key Takeaways
	â€¢	RewriteTablePath automatically updates all metadata files (JSON & Avro).
	â€¢	No manual Avro file editing is needed.
	â€¢	Ensure data is copied first before running the command.
	â€¢	Preserves Iceberg table history and snapshots.

Would you like a script to automate this migration end-to-end? ğŸš€
////

import org.apache.iceberg.spark.actions.SparkActions

val table = "my_catalog.my_db.iceberg_table" // Use your actual table name

SparkActions.get(spark)
  .rewriteTablePath(table)
  .withLocation("o3fs://mybucket.omservice/iceberg_table/")
  .execute()
