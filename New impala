#!/bin/bash

# Prompt for source table name
echo -n "Enter the source table name (schema.table): "
read source_table

# Validate input
if [ -z "$source_table" ]; then
    echo "Table name cannot be empty."
    exit 1
fi

# Define new table name
new_table="${source_table}_new_"

# Extract schema name and table name
schema_name=$(echo "$source_table" | cut -d '.' -f1)
table_name=$(echo "$source_table" | cut -d '.' -f2)

# Step 1: Fetch the schema definition and partition columns dynamically
create_table_output=$(impala-shell -B -q "SHOW CREATE TABLE $source_table" 2>/dev/null)

# Extract column definitions (before PARTITIONED BY)
columns=$(echo "$create_table_output" | awk '/CREATE TABLE/,/PARTITIONED BY/ {if (!/PARTITIONED BY/) print}' | sed '1d' | sed '/^$/d' | tr -d ',')

# Extract partition columns dynamically (removes invalid metadata like SERDEPROPERTIES)
partition_columns=$(echo "$create_table_output" | awk '/PARTITIONED BY/,/STORED AS/' | grep -v 'STORED AS' | grep -oP '\(\K[^\)]+' | tr -d ' ' | sed 's/,/ /g')

# Clean up partition columns
if [ -n "$partition_columns" ]; then
    echo "Detected Partition Columns: $partition_columns"
    partition_clause="PARTITIONED BY ($partition_columns)"
else
    echo "No partitions found. Proceeding without partitions."
    partition_clause=""
fi

# Step 2: Create the target Iceberg table dynamically
echo "Creating new Iceberg table: $new_table"

impala-shell -i usvxapinscs08.sdi.corp.bankofamerica.com:21000 --ssl -q "
CREATE TABLE $new_table (
$columns
)
$partition_clause
STORED AS ICEBERG
TBLPROPERTIES (
    'format-version' = '2',
    'parquet_annotate_strings_utf8' = 'true'
);
"

# Step 3: Insert data into the new table
echo "Loading data into $new_table..."

impala-shell -i usvxapinscs08.sdi.corp.bankofamerica.com:21000 --ssl -q "
INSERT INTO $new_table SELECT * FROM $source_table;
"

# Step 4: Validate success
if [ $? -eq 0 ]; then
    echo "Table $new_table created and data loaded successfully."
else
    echo "Failed to create the table or load data."
    exit 1
fi
